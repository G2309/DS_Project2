{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":36363,"databundleVersionId":4050810,"sourceType":"competition"},{"sourceId":4264054,"sourceType":"datasetVersion","datasetId":2406209}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!python -V\n!pip -V\n!python -c \"import sys, pkgutil; print('numpy', pkgutil.find_loader('numpy') is not None); print('torch', pkgutil.find_loader('torch') is not None)\"\n!pip install --upgrade --no-deps timm pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg\n!pip install --upgrade --no-deps pylibjpeg==2.1.0 pylibjpeg-libjpeg==2.3.0 pylibjpeg-openjpeg==2.5.0 || true\n!pip check || true","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-23T14:51:33.152847Z","iopub.execute_input":"2025-10-23T14:51:33.153395Z","execution_failed":"2025-10-23T14:51:45.238Z"}},"outputs":[{"name":"stdout","text":"Python 3.11.13\npip 24.1.2 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\nnumpy True\ntorch True\nRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.19)\nCollecting timm\n  Downloading timm-1.0.20-py3-none-any.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pylibjpeg\n  Downloading pylibjpeg-2.1.0-py3-none-any.whl.metadata (7.9 kB)\nCollecting pylibjpeg-libjpeg\n  Downloading pylibjpeg_libjpeg-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\nCollecting pylibjpeg-openjpeg\n  Downloading pylibjpeg_openjpeg-2.5.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.8 kB)\nDownloading timm-1.0.20-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pylibjpeg-2.1.0-py3-none-any.whl (25 kB)\nDownloading pylibjpeg_libjpeg-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pylibjpeg_openjpeg-2.5.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: timm, pylibjpeg-openjpeg, pylibjpeg-libjpeg, pylibjpeg\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.19\n    Uninstalling timm-1.0.19:\n      Successfully uninstalled timm-1.0.19\nSuccessfully installed pylibjpeg-2.1.0 pylibjpeg-libjpeg-2.3.0 pylibjpeg-openjpeg-2.5.0 timm-1.0.20\nRequirement already satisfied: pylibjpeg==2.1.0 in /usr/local/lib/python3.11/dist-packages (2.1.0)\nRequirement already satisfied: pylibjpeg-libjpeg==2.3.0 in /usr/local/lib/python3.11/dist-packages (2.3.0)\nRequirement already satisfied: pylibjpeg-openjpeg==2.5.0 in /usr/local/lib/python3.11/dist-packages (2.5.0)\nbigframes 2.12.0 requires google-cloud-bigquery-storage, which is not installed.\npylibjpeg-libjpeg 2.3.0 has requirement numpy<3.0,>=2.0, but you have numpy 1.26.4.\npylibjpeg-openjpeg 2.5.0 has requirement numpy<3.0,>=2.0, but you have numpy 1.26.4.\ngensim 4.3.3 has requirement scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3.\ndatasets 4.1.1 has requirement pyarrow>=21.0.0, but you have pyarrow 19.0.1.\nonnx 1.18.0 has requirement protobuf>=4.25.1, but you have protobuf 3.20.3.\ngoogle-cloud-bigtable 2.32.0 has requirement google-api-core[grpc]<3.0.0,>=2.17.0, but you have google-api-core 1.34.1.\npreprocessing 0.1.13 has requirement nltk==3.2.4, but you have nltk 3.9.1.\ncesium 0.12.4 has requirement numpy<3.0,>=2.0, but you have numpy 1.26.4.\ngoogle-colab 1.0.0 has requirement google-auth==2.38.0, but you have google-auth 2.40.3.\ngoogle-colab 1.0.0 has requirement notebook==6.5.7, but you have notebook 6.5.4.\ngoogle-colab 1.0.0 has requirement pandas==2.2.2, but you have pandas 2.2.3.\ngoogle-colab 1.0.0 has requirement requests==2.32.3, but you have requests 2.32.5.\ngoogle-colab 1.0.0 has requirement tornado==6.4.2, but you have tornado 6.5.2.\ndopamine-rl 4.1.2 has requirement gymnasium>=1.0.0, but you have gymnasium 0.29.0.\nbigframes 2.12.0 has requirement google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0.\nbigframes 2.12.0 has requirement rich<14,>=12.4.4, but you have rich 14.1.0.\nibis-framework 9.5.0 has requirement toolz<1,>=0.11, but you have toolz 1.0.0.\ntokenizers 0.21.2 has requirement huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.0rc2.\nthinc 8.3.6 has requirement numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4.\nopencv-contrib-python 4.12.0.88 has requirement numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4.\nlibcugraph-cu12 25.6.0 has requirement libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0.\nopencv-python 4.12.0.88 has requirement numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4.\ntorch 2.6.0+cu124 has requirement nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2.\ntorch 2.6.0+cu124 has requirement nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82.\ntorch 2.6.0+cu124 has requirement nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82.\ntorch 2.6.0+cu124 has requirement nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82.\ntorch 2.6.0+cu124 has requirement nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75.\ntorch 2.6.0+cu124 has requirement nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61.\ntorch 2.6.0+cu124 has requirement nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82.\ntorch 2.6.0+cu124 has requirement nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83.\ntorch 2.6.0+cu124 has requirement nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3.\ntorch 2.6.0+cu124 has requirement nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82.\ngradio 5.38.1 has requirement pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1.\ncudf-polars-cu12 25.6.0 has requirement pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2.\nmdit-py-plugins 0.4.2 has requirement markdown-it-py<4.0.0,>=1.0.0, but you have markdown-it-py 4.0.0.\ntensorflow-metadata 1.17.2 has requirement protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3.\npydrive2 1.21.3 has requirement cryptography<44, but you have cryptography 46.0.1.\npydrive2 1.21.3 has requirement pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0.\nimbalanced-learn 0.13.0 has requirement scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2.\npandas-gbq 0.29.2 has requirement google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1.\ngoogle-cloud-storage 2.19.0 has requirement google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1.\ntransformers 4.53.3 has requirement huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2.\nopencv-python-headless 4.12.0.88 has requirement numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4.\nplotnine 0.14.5 has requirement matplotlib>=3.8.0, but you have matplotlib 3.7.2.\npylibcugraph-cu12 25.6.0 has requirement pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0.\npylibcugraph-cu12 25.6.0 has requirement rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0.\njupyter-kernel-gateway 2.5.2 has requirement jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3.\numap-learn 0.5.9.post2 has requirement scikit-learn>=1.6, but you have scikit-learn 1.2.2.\ndataproc-spark-connect 0.8.3 has requirement google-api-core>=2.19, but you have google-api-core 1.34.1.\ngcsfs 2025.3.0 has requirement fsspec==2025.3.0, but you have fsspec 2025.9.0.\nmlxtend 0.23.4 has requirement scikit-learn>=1.3.1, but you have scikit-learn 1.2.2.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import os, sys\nos.kill(os.getpid(), 9)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-23T14:51:45.238Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport pydicom\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom torchvision import transforms\nfrom torchvision.models import vit_b_16, ViT_B_16_Weights\nfrom torch.cuda.amp import GradScaler, autocast\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:28:46.678796Z","iopub.execute_input":"2025-10-23T16:28:46.679463Z","iopub.status.idle":"2025-10-23T16:28:46.683985Z","shell.execute_reply.started":"2025-10-23T16:28:46.679435Z","shell.execute_reply":"2025-10-23T16:28:46.683221Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/rsna-2022-cervical-spine-fracture-detection\"\nTRAIN_IMG_DIR = os.path.join(DATA_PATH, \"train_images\")\ntrain_df = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\nstudy_ids = train_df[\"StudyInstanceUID\"].unique()\nnp.random.seed(33)\nnp.random.shuffle(study_ids)\nsplit_idx = int(len(study_ids) * 0.8)\ntrain_studies = study_ids[:split_idx]\nval_studies = study_ids[split_idx:]\ntrain_df_split = train_df[train_df[\"StudyInstanceUID\"].isin(train_studies)]\nval_df_split = train_df[train_df[\"StudyInstanceUID\"].isin(val_studies)]\n\nweights = ViT_B_16_Weights.IMAGENET1K_V1\nmean = weights.meta.get(\"mean\", [0.485, 0.456, 0.406])\nstd = weights.meta.get(\"std\", [0.229, 0.224, 0.225])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:30:01.038001Z","iopub.execute_input":"2025-10-23T16:30:01.038332Z","iopub.status.idle":"2025-10-23T16:30:01.050863Z","shell.execute_reply.started":"2025-10-23T16:30:01.038309Z","shell.execute_reply":"2025-10-23T16:30:01.050008Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## Modelo ViT","metadata":{}},{"cell_type":"code","source":"def find_optimal_thresholds(model, loader, device):\n    model.eval()\n    all_probs = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for imgs, labels in loader:\n            imgs = imgs.to(device)\n            out = model(imgs)\n            probs = torch.sigmoid(out)\n            all_probs.append(probs.cpu())\n            all_labels.append(labels.cpu())\n    \n    all_probs = torch.cat(all_probs).numpy()\n    all_labels = torch.cat(all_labels).numpy()\n    \n    optimal_thresholds = []\n    for i in range(all_labels.shape[1]):\n        best_f1 = 0\n        best_thresh = 0.5\n        for thresh in np.arange(0.3, 0.7, 0.05):\n            preds = (all_probs[:, i] > thresh).astype(int)\n            f1 = f1_score(all_labels[:, i], preds, zero_division=0)\n            if f1 > best_f1:\n                best_f1 = f1\n                best_thresh = thresh\n        optimal_thresholds.append(best_thresh)\n    \n    return optimal_thresholds\n\nclass EarlyStopping:\n    def __init__(self, patience=5, min_delta=0.001, mode='max'):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.mode = mode\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        \n    def __call__(self, score):\n        if self.best_score is None:\n            self.best_score = score\n        elif self.mode == 'max':\n            if score < self.best_score + self.min_delta:\n                self.counter += 1\n                if self.counter >= self.patience:\n                    self.early_stop = True\n            else:\n                self.best_score = score\n                self.counter = 0\n        return self.early_stop\n\nclass CervicalSliceDataset(Dataset):\n    def __init__(self, df, root, transform=None, num_slices=5):\n        self.df = df\n        self.root = root\n        self.transform = transform\n        self.num_slices = num_slices\n        self.study_ids = df[\"StudyInstanceUID\"].unique().tolist()\n    def __len__(self):\n        return len(self.study_ids)\n    def __getitem__(self, idx):\n        study = self.study_ids[idx]\n        folder = os.path.join(self.root, study)\n        files = sorted([f for f in os.listdir(folder) if f.endswith(\".dcm\")])\n        if len(files) == 0:\n            raise RuntimeError(folder)\n        mid = len(files) // 2\n        idxs = []\n        if self.num_slices >= 3:\n            idxs = [max(0, mid-1), mid, min(len(files)-1, mid+1)]\n        else:\n            idxs = [mid, mid, mid]\n        slices = []\n        for i in idxs:\n            path = os.path.join(folder, files[i])\n            ds = pydicom.dcmread(path)\n            slope = float(getattr(ds, \"RescaleSlope\", 1.0))\n            intercept = float(getattr(ds, \"RescaleIntercept\", 0.0))\n            arr = ds.pixel_array.astype(np.float32) * slope + intercept\n            arr = arr - arr.min()\n            if arr.max() > 0:\n                arr = arr / arr.max()\n            arr = (arr * 255).astype(np.uint8)\n            img = Image.fromarray(arr).convert(\"L\")\n            if self.transform:\n                img = self.transform(img.convert(\"RGB\"))\n            slices.append(img)\n        img_tensor = torch.stack(slices)\n        img_tensor = torch.mean(img_tensor, dim=0)\n        row = self.df[self.df[\"StudyInstanceUID\"]==study].iloc[0]\n        labels = torch.zeros(8, dtype=torch.float32)\n        labels[0] = row[\"patient_overall\"]\n        for i in range(1,8):\n            labels[i] = row[f\"C{i}\"]\n        return img_tensor, labels\n\ntrain_transforms = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.RandomRotation(12),\n    transforms.RandomHorizontalFlip(0.2),\n    transforms.ColorJitter(brightness=0.15, contrast=0.15),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\n\n\ntrain_ds = CervicalSliceDataset(train_df_split, TRAIN_IMG_DIR, transform=train_transforms, num_slices=5)\nval_ds = CervicalSliceDataset(val_df_split, TRAIN_IMG_DIR, transform=val_transforms, num_slices=5)\n\ntrain_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=0, pin_memory=False)\nval_loader = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=0, pin_memory=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:30:03.555715Z","iopub.execute_input":"2025-10-23T16:30:03.556038Z","iopub.status.idle":"2025-10-23T16:30:03.581398Z","shell.execute_reply.started":"2025-10-23T16:30:03.556013Z","shell.execute_reply":"2025-10-23T16:30:03.580701Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"pos_counts = train_df_split.iloc[:, 1:9].sum().values\npos_counts = np.clip(pos_counts, 1, None)\nneg_counts = len(train_df_split) - pos_counts\npos_weight = torch.tensor((neg_counts / pos_counts).astype(np.float32))\npos_weight = torch.clamp(pos_weight, max=100.0)\n\nlabels_for_sampler = train_df_split.iloc[:, 1:9].sum(axis=1).values\nsample_weights = 1.0 / (labels_for_sampler + 1.0)\nsample_weights = sample_weights / sample_weights.sum()\nsampler = None\ntry:\n    class_counts = train_df_split.iloc[:, 1:9].sum(axis=0).values\n    sample_weights_per_study = []\n    for s in train_ds.study_ids:\n        row = train_df_split[train_df_split[\"StudyInstanceUID\"]==s].iloc[0]\n        c = row.iloc[1:9].sum()\n        sample_weights_per_study.append(1.0/(c+1.0))\n    sampler = WeightedRandomSampler(sample_weights_per_study, num_samples=len(sample_weights_per_study), replacement=True)\nexcept Exception:\n    sampler = None\n\nbatch_size = 64\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=(sampler is None), sampler=sampler, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = vit_b_16(weights=weights)\nin_features = model.heads.head.in_features if hasattr(model, \"heads\") else model.head.in_features\ntry:\n    model.heads.head = torch.nn.Linear(in_features, 8)\nexcept Exception:\n    model.head = torch.nn.Linear(in_features, 8)\nmodel = model.to(device)\n\nfor param in model.parameters():\n    param.requires_grad = True\n\ndef freeze_backbone(m):\n    for n,p in m.named_parameters():\n        if \"head\" not in n and \"heads\" not in n:\n            p.requires_grad = False\n\nfreeze_backbone(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:30:06.723983Z","iopub.execute_input":"2025-10-23T16:30:06.724263Z","iopub.status.idle":"2025-10-23T16:30:08.903445Z","shell.execute_reply.started":"2025-10-23T16:30:06.724238Z","shell.execute_reply":"2025-10-23T16:30:08.902792Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\noptimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-4, weight_decay=0.01)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\nscaler = GradScaler() if torch.cuda.is_available() else None\naccum_steps = 1\n\ndef train_epoch(model, loader, optimizer, criterion, device, scaler=None, accum_steps=1):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    optimizer.zero_grad()\n    for step, (imgs, labels) in enumerate(tqdm(loader, desc=\"Training\")):\n        imgs = imgs.to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n        if scaler is not None:\n            with autocast():\n                out = model(imgs)\n                loss = criterion(out, labels) / accum_steps\n            scaler.scale(loss).backward()\n            if (step + 1) % accum_steps == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n        else:\n            out = model(imgs)\n            loss = criterion(out, labels) / accum_steps\n            loss.backward()\n            if (step + 1) % accum_steps == 0:\n                optimizer.step()\n                optimizer.zero_grad()\n        running_loss += loss.item() * imgs.size(0) * accum_steps\n        preds = (torch.sigmoid(out) > 0.5).float()\n        correct += (preds == labels).sum().item()\n        total += labels.numel()\n    return running_loss / len(loader.dataset), correct / total\n\ndef validate(model, loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for imgs, labels in tqdm(loader, desc=\"Validation\"):\n            imgs = imgs.to(device, non_blocking=True)\n            labels = labels.to(device, non_blocking=True)\n            with autocast(enabled=(scaler is not None)):\n                out = model(imgs)\n                loss = criterion(out, labels)\n            running_loss += loss.item() * imgs.size(0)\n            preds = (torch.sigmoid(out) > 0.5).float()\n            correct += (preds == labels).sum().item()\n            total += labels.numel()\n    return running_loss / len(loader.dataset), correct / total\n\nresults = []\nbest_val_acc = 0.0\nunfreeze_epoch = 3\nfor epoch in range(1, 16):\n    if epoch == unfreeze_epoch:\n        for p in model.parameters():\n            p.requires_grad = True\n        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=12, eta_min=1e-6)\n    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device, scaler, accum_steps)\n    val_loss, val_acc = validate(model, val_loader, criterion, device)\n    scheduler.step()\n    results.append({'epoch': epoch, 'train_loss': train_loss, 'train_accuracy': train_acc, 'val_loss': val_loss, 'val_accuracy': val_acc, 'lr': optimizer.param_groups[0]['lr']})\n    print(f\"Epoch {epoch}: train_loss={train_loss:.4f}, train_acc={train_acc:.4f}, val_loss={val_loss:.4f}, val_acc={val_acc:.4f}, lr={optimizer.param_groups[0]['lr']:.2e}\")\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), 'best_vit_model_pre.pth')\n\npd.DataFrame(results).to_csv('training_results_vit.csv', index=False)\nprint(best_val_acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:30:12.589298Z","iopub.execute_input":"2025-10-23T16:30:12.589844Z","iopub.status.idle":"2025-10-23T16:41:11.014535Z","shell.execute_reply.started":"2025-10-23T16:30:12.589815Z","shell.execute_reply":"2025-10-23T16:41:11.013668Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_103/3082461450.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler() if torch.cuda.is_available() else None\nTraining:   0%|          | 0/26 [00:00<?, ?it/s]/tmp/ipykernel_103/3082461450.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nTraining: 100%|██████████| 26/26 [00:40<00:00,  1.55s/it]\nValidation:   0%|          | 0/7 [00:00<?, ?it/s]/tmp/ipykernel_103/3082461450.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=(scaler is not None)):\nValidation: 100%|██████████| 7/7 [00:12<00:00,  1.83s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: train_loss=0.7961, train_acc=0.8429, val_loss=1.4476, val_acc=0.8308, lr=1.95e-04\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 26/26 [00:34<00:00,  1.31s/it]\nValidation: 100%|██████████| 7/7 [00:07<00:00,  1.08s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: train_loss=0.7747, train_acc=0.9318, val_loss=1.4919, val_acc=0.8363, lr=1.81e-04\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 26/26 [00:35<00:00,  1.36s/it]\nValidation: 100%|██████████| 7/7 [00:07<00:00,  1.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: train_loss=0.7290, train_acc=0.9338, val_loss=1.6160, val_acc=0.8441, lr=9.85e-06\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 26/26 [00:35<00:00,  1.37s/it]\nValidation: 100%|██████████| 7/7 [00:07<00:00,  1.08s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: train_loss=0.7596, train_acc=0.9352, val_loss=1.5337, val_acc=0.8416, lr=9.40e-06\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 26/26 [00:36<00:00,  1.40s/it]\nValidation: 100%|██████████| 7/7 [00:07<00:00,  1.07s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: train_loss=0.7523, train_acc=0.9318, val_loss=1.5165, val_acc=0.8431, lr=8.68e-06\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 26/26 [00:35<00:00,  1.37s/it]\nValidation: 100%|██████████| 7/7 [00:07<00:00,  1.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: train_loss=0.7005, train_acc=0.9347, val_loss=1.6251, val_acc=0.8431, lr=7.75e-06\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 26/26 [00:35<00:00,  1.35s/it]\nValidation: 100%|██████████| 7/7 [00:07<00:00,  1.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: train_loss=0.6939, train_acc=0.9358, val_loss=1.5928, val_acc=0.8444, lr=6.66e-06\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 26/26 [00:35<00:00,  1.36s/it]\nValidation: 100%|██████████| 7/7 [00:07<00:00,  1.05s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: train_loss=0.6867, train_acc=0.9359, val_loss=1.5408, val_acc=0.8441, lr=5.50e-06\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 26/26 [00:34<00:00,  1.32s/it]\nValidation: 100%|██████████| 7/7 [00:07<00:00,  1.03s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: train_loss=0.6777, train_acc=0.9302, val_loss=1.5703, val_acc=0.8428, lr=4.34e-06\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 26/26 [00:36<00:00,  1.39s/it]\nValidation: 100%|██████████| 7/7 [00:07<00:00,  1.05s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: train_loss=0.6447, train_acc=0.9386, val_loss=1.6017, val_acc=0.8431, lr=3.25e-06\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 26/26 [00:35<00:00,  1.35s/it]\nValidation: 100%|██████████| 7/7 [00:07<00:00,  1.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: train_loss=0.6113, train_acc=0.9381, val_loss=1.6483, val_acc=0.8434, lr=2.32e-06\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 26/26 [00:35<00:00,  1.37s/it]\nValidation: 100%|██████████| 7/7 [00:07<00:00,  1.05s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: train_loss=0.6418, train_acc=0.9322, val_loss=1.6165, val_acc=0.8428, lr=1.60e-06\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 26/26 [00:36<00:00,  1.42s/it]\nValidation: 100%|██████████| 7/7 [00:07<00:00,  1.07s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: train_loss=0.6049, train_acc=0.9368, val_loss=1.6518, val_acc=0.8431, lr=1.15e-06\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 26/26 [00:35<00:00,  1.38s/it]\nValidation: 100%|██████████| 7/7 [00:07<00:00,  1.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: train_loss=0.6326, train_acc=0.9330, val_loss=1.6314, val_acc=0.8422, lr=1.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 26/26 [00:36<00:00,  1.41s/it]\nValidation: 100%|██████████| 7/7 [00:07<00:00,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 15: train_loss=0.6804, train_acc=0.9278, val_loss=1.5871, val_acc=0.8425, lr=1.15e-06\n0.8443688118811881\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/working/training_results_vit.csv')\ndf.head(15)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:41:23.228483Z","iopub.execute_input":"2025-10-23T16:41:23.228804Z","iopub.status.idle":"2025-10-23T16:41:23.243704Z","shell.execute_reply.started":"2025-10-23T16:41:23.228777Z","shell.execute_reply":"2025-10-23T16:41:23.243077Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"    epoch  train_loss  train_accuracy  val_loss  val_accuracy        lr\n0       1    0.796100        0.842879  1.447615      0.830755  0.000195\n1       2    0.774688        0.931811  1.491851      0.836324  0.000181\n2       3    0.729016        0.933824  1.615965      0.844059  0.000010\n3       4    0.759563        0.935217  1.533693      0.841584  0.000009\n4       5    0.752276        0.931811  1.516464      0.843131  0.000009\n5       6    0.700549        0.934675  1.625093      0.843131  0.000008\n6       7    0.693887        0.935836  1.592806      0.844369  0.000007\n7       8    0.686654        0.935913  1.540804      0.844059  0.000006\n8       9    0.677727        0.930186  1.570296      0.842822  0.000004\n9      10    0.644720        0.938622  1.601733      0.843131  0.000003\n10     11    0.611344        0.938080  1.648297      0.843441  0.000002\n11     12    0.641832        0.932198  1.616518      0.842822  0.000002\n12     13    0.604871        0.936765  1.651786      0.843131  0.000001\n13     14    0.632564        0.933050  1.631420      0.842203  0.000001\n14     15    0.680413        0.927786  1.587104      0.842512  0.000001","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>train_accuracy</th>\n      <th>val_loss</th>\n      <th>val_accuracy</th>\n      <th>lr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.796100</td>\n      <td>0.842879</td>\n      <td>1.447615</td>\n      <td>0.830755</td>\n      <td>0.000195</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.774688</td>\n      <td>0.931811</td>\n      <td>1.491851</td>\n      <td>0.836324</td>\n      <td>0.000181</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.729016</td>\n      <td>0.933824</td>\n      <td>1.615965</td>\n      <td>0.844059</td>\n      <td>0.000010</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.759563</td>\n      <td>0.935217</td>\n      <td>1.533693</td>\n      <td>0.841584</td>\n      <td>0.000009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.752276</td>\n      <td>0.931811</td>\n      <td>1.516464</td>\n      <td>0.843131</td>\n      <td>0.000009</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0.700549</td>\n      <td>0.934675</td>\n      <td>1.625093</td>\n      <td>0.843131</td>\n      <td>0.000008</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0.693887</td>\n      <td>0.935836</td>\n      <td>1.592806</td>\n      <td>0.844369</td>\n      <td>0.000007</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0.686654</td>\n      <td>0.935913</td>\n      <td>1.540804</td>\n      <td>0.844059</td>\n      <td>0.000006</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0.677727</td>\n      <td>0.930186</td>\n      <td>1.570296</td>\n      <td>0.842822</td>\n      <td>0.000004</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>0.644720</td>\n      <td>0.938622</td>\n      <td>1.601733</td>\n      <td>0.843131</td>\n      <td>0.000003</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>0.611344</td>\n      <td>0.938080</td>\n      <td>1.648297</td>\n      <td>0.843441</td>\n      <td>0.000002</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>0.641832</td>\n      <td>0.932198</td>\n      <td>1.616518</td>\n      <td>0.842822</td>\n      <td>0.000002</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>0.604871</td>\n      <td>0.936765</td>\n      <td>1.651786</td>\n      <td>0.843131</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>0.632564</td>\n      <td>0.933050</td>\n      <td>1.631420</td>\n      <td>0.842203</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>0.680413</td>\n      <td>0.927786</td>\n      <td>1.587104</td>\n      <td>0.842512</td>\n      <td>0.000001</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}