{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":36363,"databundleVersionId":4050810,"sourceType":"competition"},{"sourceId":4264054,"sourceType":"datasetVersion","datasetId":2406209}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!python -V\n!pip -V\n!python -c \"import sys, pkgutil; print('numpy', pkgutil.find_loader('numpy') is not None); print('torch', pkgutil.find_loader('torch') is not None)\"\n!pip install --upgrade --no-deps timm pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg\n!pip install --upgrade --no-deps pylibjpeg==2.1.0 pylibjpeg-libjpeg==2.3.0 pylibjpeg-openjpeg==2.5.0 || true\n!pip check || true","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-23T00:02:40.904213Z","iopub.execute_input":"2025-10-23T00:02:40.904550Z","iopub.status.idle":"2025-10-23T00:02:47.685881Z","shell.execute_reply.started":"2025-10-23T00:02:40.904526Z","shell.execute_reply":"2025-10-23T00:02:47.684822Z"}},"outputs":[{"name":"stdout","text":"Python 3.11.13\npip 24.1.2 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\nnumpy True\ntorch True\nRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.20)\nRequirement already satisfied: pylibjpeg in /usr/local/lib/python3.11/dist-packages (2.1.0)\nRequirement already satisfied: pylibjpeg-libjpeg in /usr/local/lib/python3.11/dist-packages (2.3.0)\nRequirement already satisfied: pylibjpeg-openjpeg in /usr/local/lib/python3.11/dist-packages (2.5.0)\nRequirement already satisfied: pylibjpeg==2.1.0 in /usr/local/lib/python3.11/dist-packages (2.1.0)\nRequirement already satisfied: pylibjpeg-libjpeg==2.3.0 in /usr/local/lib/python3.11/dist-packages (2.3.0)\nRequirement already satisfied: pylibjpeg-openjpeg==2.5.0 in /usr/local/lib/python3.11/dist-packages (2.5.0)\nbigframes 2.12.0 requires google-cloud-bigquery-storage, which is not installed.\npylibjpeg-libjpeg 2.3.0 has requirement numpy<3.0,>=2.0, but you have numpy 1.26.4.\npylibjpeg-openjpeg 2.5.0 has requirement numpy<3.0,>=2.0, but you have numpy 1.26.4.\ngensim 4.3.3 has requirement scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3.\ndatasets 4.1.1 has requirement pyarrow>=21.0.0, but you have pyarrow 19.0.1.\nonnx 1.18.0 has requirement protobuf>=4.25.1, but you have protobuf 3.20.3.\ngoogle-cloud-bigtable 2.32.0 has requirement google-api-core[grpc]<3.0.0,>=2.17.0, but you have google-api-core 1.34.1.\npreprocessing 0.1.13 has requirement nltk==3.2.4, but you have nltk 3.9.1.\ncesium 0.12.4 has requirement numpy<3.0,>=2.0, but you have numpy 1.26.4.\ngoogle-colab 1.0.0 has requirement google-auth==2.38.0, but you have google-auth 2.40.3.\ngoogle-colab 1.0.0 has requirement notebook==6.5.7, but you have notebook 6.5.4.\ngoogle-colab 1.0.0 has requirement pandas==2.2.2, but you have pandas 2.2.3.\ngoogle-colab 1.0.0 has requirement requests==2.32.3, but you have requests 2.32.5.\ngoogle-colab 1.0.0 has requirement tornado==6.4.2, but you have tornado 6.5.2.\ndopamine-rl 4.1.2 has requirement gymnasium>=1.0.0, but you have gymnasium 0.29.0.\nbigframes 2.12.0 has requirement google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0.\nbigframes 2.12.0 has requirement rich<14,>=12.4.4, but you have rich 14.1.0.\nibis-framework 9.5.0 has requirement toolz<1,>=0.11, but you have toolz 1.0.0.\ntokenizers 0.21.2 has requirement huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.0rc2.\nthinc 8.3.6 has requirement numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4.\nopencv-contrib-python 4.12.0.88 has requirement numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4.\nlibcugraph-cu12 25.6.0 has requirement libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0.\nopencv-python 4.12.0.88 has requirement numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4.\ntorch 2.6.0+cu124 has requirement nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2.\ntorch 2.6.0+cu124 has requirement nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82.\ntorch 2.6.0+cu124 has requirement nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82.\ntorch 2.6.0+cu124 has requirement nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82.\ntorch 2.6.0+cu124 has requirement nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75.\ntorch 2.6.0+cu124 has requirement nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61.\ntorch 2.6.0+cu124 has requirement nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82.\ntorch 2.6.0+cu124 has requirement nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83.\ntorch 2.6.0+cu124 has requirement nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3.\ntorch 2.6.0+cu124 has requirement nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82.\ngradio 5.38.1 has requirement pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1.\ncudf-polars-cu12 25.6.0 has requirement pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2.\nmdit-py-plugins 0.4.2 has requirement markdown-it-py<4.0.0,>=1.0.0, but you have markdown-it-py 4.0.0.\ntensorflow-metadata 1.17.2 has requirement protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3.\npydrive2 1.21.3 has requirement cryptography<44, but you have cryptography 46.0.1.\npydrive2 1.21.3 has requirement pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0.\nimbalanced-learn 0.13.0 has requirement scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2.\npandas-gbq 0.29.2 has requirement google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1.\ngoogle-cloud-storage 2.19.0 has requirement google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1.\ntransformers 4.53.3 has requirement huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2.\nopencv-python-headless 4.12.0.88 has requirement numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4.\nplotnine 0.14.5 has requirement matplotlib>=3.8.0, but you have matplotlib 3.7.2.\npylibcugraph-cu12 25.6.0 has requirement pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0.\npylibcugraph-cu12 25.6.0 has requirement rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0.\njupyter-kernel-gateway 2.5.2 has requirement jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3.\numap-learn 0.5.9.post2 has requirement scikit-learn>=1.6, but you have scikit-learn 1.2.2.\ndataproc-spark-connect 0.8.3 has requirement google-api-core>=2.19, but you have google-api-core 1.34.1.\ngcsfs 2025.3.0 has requirement fsspec==2025.3.0, but you have fsspec 2025.9.0.\nmlxtend 0.23.4 has requirement scikit-learn>=1.3.1, but you have scikit-learn 1.2.2.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import os, sys\nos.kill(os.getpid(), 9)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-23T00:03:19.629Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport pydicom\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torch.cuda.amp import autocast, GradScaler\nimport timm\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T00:03:32.698774Z","iopub.execute_input":"2025-10-23T00:03:32.699504Z","iopub.status.idle":"2025-10-23T00:03:37.647616Z","shell.execute_reply.started":"2025-10-23T00:03:32.699479Z","shell.execute_reply":"2025-10-23T00:03:37.647020Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/rsna-2022-cervical-spine-fracture-detection\"\ntrain_df = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\ntest_df = pd.read_csv(os.path.join(DATA_PATH, \"test.csv\"))\nsample_sub = pd.read_csv(os.path.join(DATA_PATH, \"sample_submission.csv\"))\nTRAIN_IMG_DIR = os.path.join(DATA_PATH, \"train_images\")","metadata":{"execution":{"iopub.status.busy":"2025-10-23T00:03:37.648697Z","iopub.execute_input":"2025-10-23T00:03:37.648888Z","iopub.status.idle":"2025-10-23T00:03:37.663548Z","shell.execute_reply.started":"2025-10-23T00:03:37.648873Z","shell.execute_reply":"2025-10-23T00:03:37.662784Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class CervicalSliceDataset(Dataset):\n    def __init__(self, df, root, transform=None):\n        self.df = df\n        self.root = root\n        self.transform = transform\n        self.study_ids = df[\"StudyInstanceUID\"].unique().tolist()\n    def __len__(self):\n        return len(self.study_ids)\n    def __getitem__(self, idx):\n        study = self.study_ids[idx]\n        folder = os.path.join(self.root, study)\n        files = sorted([f for f in os.listdir(folder) if f.endswith(\".dcm\")])\n        if len(files) == 0:\n            raise RuntimeError(f\"No DICOM in {folder}\")\n        chosen = files[len(files)//2]\n        path = os.path.join(folder, chosen)\n        ds = pydicom.dcmread(path)\n        try:\n            arr = ds.pixel_array\n        except Exception:\n            ds.decompress()\n            arr = ds.pixel_array\n        if arr.ndim == 3:\n            arr = arr[0]\n        img = Image.fromarray(arr).convert(\"L\")\n        if self.transform:\n            img = self.transform(img)\n        row = self.df[self.df[\"StudyInstanceUID\"]==study].iloc[0]\n        labels = torch.zeros(8, dtype=torch.float32)\n        labels[0] = row[\"patient_overall\"]\n        for i in range(1,8):\n            labels[i] = row[f\"C{i}\"]\n        return img, labels\n\n\ntrain_transforms = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.RandomRotation(10),\n    transforms.Grayscale(num_output_channels=3),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n])\ntrain_ds = CervicalSliceDataset(train_df, TRAIN_IMG_DIR, transform=train_transforms)\ntrain_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T00:03:37.664465Z","iopub.execute_input":"2025-10-23T00:03:37.664749Z","iopub.status.idle":"2025-10-23T00:03:37.675761Z","shell.execute_reply.started":"2025-10-23T00:03:37.664731Z","shell.execute_reply":"2025-10-23T00:03:37.675021Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Modelo ViT","metadata":{}},{"cell_type":"code","source":"# Para pruebas cpu y para el final si usare gpu cuda\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=8)\nmodel = model.to(device)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-5, weight_decay=1e-2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T00:03:37.676973Z","iopub.execute_input":"2025-10-23T00:03:37.677701Z","iopub.status.idle":"2025-10-23T00:03:39.639589Z","shell.execute_reply.started":"2025-10-23T00:03:37.677674Z","shell.execute_reply":"2025-10-23T00:03:39.639012Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"scaler = GradScaler() if torch.cuda.is_available() else None\n\ndef train_epoch(model, loader, optimizer, criterion, device, scaler=None):\n    model.train()\n    running_loss = 0.0\n    for imgs, labels in tqdm(loader):\n        imgs = imgs.to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n        optimizer.zero_grad()\n        if scaler is not None:\n            with autocast():\n                out = model(imgs)\n                loss = criterion(out, labels)\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            out = model(imgs)\n            loss = criterion(out, labels)\n            loss.backward()\n            optimizer.step()\n        running_loss += loss.item() * imgs.size(0)\n    return running_loss / len(loader.dataset)\n\nfor epoch in range(1,4):\n    loss = train_epoch(model, train_loader, optimizer, criterion, device, scaler)\n    print(f\"epoch {epoch} loss {loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T00:03:39.640291Z","iopub.execute_input":"2025-10-23T00:03:39.640503Z","iopub.status.idle":"2025-10-23T00:05:25.539941Z","shell.execute_reply.started":"2025-10-23T00:03:39.640487Z","shell.execute_reply":"2025-10-23T00:05:25.539093Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_227/1633072353.py:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler() if torch.cuda.is_available() else None\n  0%|          | 0/127 [00:00<?, ?it/s]/tmp/ipykernel_227/1633072353.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n100%|██████████| 127/127 [01:02<00:00,  2.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 1 loss 0.3788\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 127/127 [00:21<00:00,  5.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 2 loss 0.3671\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 127/127 [00:22<00:00,  5.76it/s]","output_type":"stream"},{"name":"stdout","text":"epoch 3 loss 0.3615\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":5}]}