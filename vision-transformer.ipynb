{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":36363,"databundleVersionId":4050810,"sourceType":"competition"},{"sourceId":4264054,"sourceType":"datasetVersion","datasetId":2406209}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!python -V\n!pip -V\n!python -c \"import sys, pkgutil; print('numpy', pkgutil.find_loader('numpy') is not None); print('torch', pkgutil.find_loader('torch') is not None)\"\n!pip install --upgrade --no-deps timm pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg\n!pip check || true","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-22T23:57:16.132391Z","iopub.execute_input":"2025-10-22T23:57:16.132721Z","iopub.status.idle":"2025-10-22T23:57:25.292555Z","shell.execute_reply.started":"2025-10-22T23:57:16.132690Z","shell.execute_reply":"2025-10-22T23:57:25.291498Z"}},"outputs":[{"name":"stdout","text":"Python 3.11.13\npip 24.1.2 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\nnumpy True\ntorch True\nRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.19)\nCollecting timm\n  Downloading timm-1.0.20-py3-none-any.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pylibjpeg\n  Downloading pylibjpeg-2.1.0-py3-none-any.whl.metadata (7.9 kB)\nCollecting pylibjpeg-libjpeg\n  Downloading pylibjpeg_libjpeg-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\nCollecting pylibjpeg-openjpeg\n  Downloading pylibjpeg_openjpeg-2.5.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.8 kB)\nDownloading timm-1.0.20-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pylibjpeg-2.1.0-py3-none-any.whl (25 kB)\nDownloading pylibjpeg_libjpeg-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pylibjpeg_openjpeg-2.5.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: timm, pylibjpeg-openjpeg, pylibjpeg-libjpeg, pylibjpeg\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.19\n    Uninstalling timm-1.0.19:\n      Successfully uninstalled timm-1.0.19\nSuccessfully installed pylibjpeg-2.1.0 pylibjpeg-libjpeg-2.3.0 pylibjpeg-openjpeg-2.5.0 timm-1.0.20\nbigframes 2.12.0 requires google-cloud-bigquery-storage, which is not installed.\npylibjpeg-libjpeg 2.3.0 has requirement numpy<3.0,>=2.0, but you have numpy 1.26.4.\npylibjpeg-openjpeg 2.5.0 has requirement numpy<3.0,>=2.0, but you have numpy 1.26.4.\ngensim 4.3.3 has requirement scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3.\ndatasets 4.1.1 has requirement pyarrow>=21.0.0, but you have pyarrow 19.0.1.\nonnx 1.18.0 has requirement protobuf>=4.25.1, but you have protobuf 3.20.3.\ngoogle-cloud-bigtable 2.32.0 has requirement google-api-core[grpc]<3.0.0,>=2.17.0, but you have google-api-core 1.34.1.\npreprocessing 0.1.13 has requirement nltk==3.2.4, but you have nltk 3.9.1.\ncesium 0.12.4 has requirement numpy<3.0,>=2.0, but you have numpy 1.26.4.\ngoogle-colab 1.0.0 has requirement google-auth==2.38.0, but you have google-auth 2.40.3.\ngoogle-colab 1.0.0 has requirement notebook==6.5.7, but you have notebook 6.5.4.\ngoogle-colab 1.0.0 has requirement pandas==2.2.2, but you have pandas 2.2.3.\ngoogle-colab 1.0.0 has requirement requests==2.32.3, but you have requests 2.32.5.\ngoogle-colab 1.0.0 has requirement tornado==6.4.2, but you have tornado 6.5.2.\ndopamine-rl 4.1.2 has requirement gymnasium>=1.0.0, but you have gymnasium 0.29.0.\nbigframes 2.12.0 has requirement google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0.\nbigframes 2.12.0 has requirement rich<14,>=12.4.4, but you have rich 14.1.0.\nibis-framework 9.5.0 has requirement toolz<1,>=0.11, but you have toolz 1.0.0.\ntokenizers 0.21.2 has requirement huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.0rc2.\nthinc 8.3.6 has requirement numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4.\nopencv-contrib-python 4.12.0.88 has requirement numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4.\nlibcugraph-cu12 25.6.0 has requirement libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0.\nopencv-python 4.12.0.88 has requirement numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4.\ntorch 2.6.0+cu124 has requirement nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2.\ntorch 2.6.0+cu124 has requirement nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82.\ntorch 2.6.0+cu124 has requirement nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82.\ntorch 2.6.0+cu124 has requirement nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82.\ntorch 2.6.0+cu124 has requirement nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75.\ntorch 2.6.0+cu124 has requirement nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61.\ntorch 2.6.0+cu124 has requirement nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82.\ntorch 2.6.0+cu124 has requirement nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83.\ntorch 2.6.0+cu124 has requirement nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3.\ntorch 2.6.0+cu124 has requirement nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82.\ngradio 5.38.1 has requirement pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1.\ncudf-polars-cu12 25.6.0 has requirement pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2.\nmdit-py-plugins 0.4.2 has requirement markdown-it-py<4.0.0,>=1.0.0, but you have markdown-it-py 4.0.0.\ntensorflow-metadata 1.17.2 has requirement protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3.\npydrive2 1.21.3 has requirement cryptography<44, but you have cryptography 46.0.1.\npydrive2 1.21.3 has requirement pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0.\nimbalanced-learn 0.13.0 has requirement scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2.\npandas-gbq 0.29.2 has requirement google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1.\ngoogle-cloud-storage 2.19.0 has requirement google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1.\ntransformers 4.53.3 has requirement huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2.\nopencv-python-headless 4.12.0.88 has requirement numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4.\nplotnine 0.14.5 has requirement matplotlib>=3.8.0, but you have matplotlib 3.7.2.\npylibcugraph-cu12 25.6.0 has requirement pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0.\npylibcugraph-cu12 25.6.0 has requirement rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0.\njupyter-kernel-gateway 2.5.2 has requirement jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3.\numap-learn 0.5.9.post2 has requirement scikit-learn>=1.6, but you have scikit-learn 1.2.2.\ndataproc-spark-connect 0.8.3 has requirement google-api-core>=2.19, but you have google-api-core 1.34.1.\ngcsfs 2025.3.0 has requirement fsspec==2025.3.0, but you have fsspec 2025.9.0.\nmlxtend 0.23.4 has requirement scikit-learn>=1.3.1, but you have scikit-learn 1.2.2.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport pydicom\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torch.cuda.amp import autocast, GradScaler\nimport timm\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T23:57:25.294286Z","iopub.execute_input":"2025-10-22T23:57:25.294625Z","iopub.status.idle":"2025-10-22T23:57:25.300198Z","shell.execute_reply.started":"2025-10-22T23:57:25.294592Z","shell.execute_reply":"2025-10-22T23:57:25.299435Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/rsna-2022-cervical-spine-fracture-detection\"\ntrain_df = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\ntest_df = pd.read_csv(os.path.join(DATA_PATH, \"test.csv\"))\nsample_sub = pd.read_csv(os.path.join(DATA_PATH, \"sample_submission.csv\"))\nTRAIN_IMG_DIR = os.path.join(DATA_PATH, \"train_images\")","metadata":{"execution":{"iopub.status.busy":"2025-10-22T23:57:25.300932Z","iopub.execute_input":"2025-10-22T23:57:25.301270Z","iopub.status.idle":"2025-10-22T23:57:25.333254Z","shell.execute_reply.started":"2025-10-22T23:57:25.301250Z","shell.execute_reply":"2025-10-22T23:57:25.332653Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class CervicalSliceDataset(Dataset):\n    def __init__(self, df, root, transform=None):\n        self.df = df\n        self.root = root\n        self.transform = transform\n        self.study_ids = df[\"StudyInstanceUID\"].unique().tolist()\n    def __len__(self):\n        return len(self.study_ids)\n    def __getitem__(self, idx):\n        study = self.study_ids[idx]\n        folder = os.path.join(self.root, study)\n        files = sorted([f for f in os.listdir(folder) if f.endswith(\".dcm\")])\n        if len(files) == 0:\n            raise RuntimeError(f\"No DICOM in {folder}\")\n        chosen = files[len(files)//2]\n        path = os.path.join(folder, chosen)\n        ds = pydicom.dcmread(path)\n        try:\n            arr = ds.pixel_array\n        except Exception:\n            ds.decompress()\n            arr = ds.pixel_array\n        if arr.ndim == 3:\n            arr = arr[0]\n        img = Image.fromarray(arr).convert(\"L\")\n        if self.transform:\n            img = self.transform(img)\n        row = self.df[self.df[\"StudyInstanceUID\"]==study].iloc[0]\n        labels = torch.zeros(8, dtype=torch.float32)\n        labels[0] = row[\"patient_overall\"]\n        for i in range(1,8):\n            labels[i] = row[f\"C{i}\"]\n        return img, labels\n\n\ntrain_transforms = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.RandomRotation(10),\n    transforms.Grayscale(num_output_channels=3),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n])\ntrain_ds = CervicalSliceDataset(train_df, TRAIN_IMG_DIR, transform=train_transforms)\ntrain_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T23:57:25.334100Z","iopub.execute_input":"2025-10-22T23:57:25.334361Z","iopub.status.idle":"2025-10-22T23:57:25.346242Z","shell.execute_reply.started":"2025-10-22T23:57:25.334340Z","shell.execute_reply":"2025-10-22T23:57:25.345448Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Modelo ViT","metadata":{}},{"cell_type":"code","source":"# Para pruebas cpu y para el final si usare gpu cuda\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=8)\nmodel = model.to(device)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-5, weight_decay=1e-2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T23:57:25.347953Z","iopub.execute_input":"2025-10-22T23:57:25.348140Z","iopub.status.idle":"2025-10-22T23:57:27.034861Z","shell.execute_reply.started":"2025-10-22T23:57:25.348126Z","shell.execute_reply":"2025-10-22T23:57:27.034258Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"scaler = GradScaler() if torch.cuda.is_available() else None\n\ndef train_epoch(model, loader, optimizer, criterion, device, scaler=None):\n    model.train()\n    running_loss = 0.0\n    for imgs, labels in tqdm(loader):\n        imgs = imgs.to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n        optimizer.zero_grad()\n        if scaler is not None:\n            with autocast():\n                out = model(imgs)\n                loss = criterion(out, labels)\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            out = model(imgs)\n            loss = criterion(out, labels)\n            loss.backward()\n            optimizer.step()\n        running_loss += loss.item() * imgs.size(0)\n    return running_loss / len(loader.dataset)\n\nfor epoch in range(1,4):\n    loss = train_epoch(model, train_loader, optimizer, criterion, device, scaler)\n    print(f\"epoch {epoch} loss {loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T23:57:27.035533Z","iopub.execute_input":"2025-10-22T23:57:27.035743Z","iopub.status.idle":"2025-10-22T23:57:27.673734Z","shell.execute_reply.started":"2025-10-22T23:57:27.035727Z","shell.execute_reply":"2025-10-22T23:57:27.672253Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_37/1633072353.py:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler() if torch.cuda.is_available() else None\n  0%|          | 0/127 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/1633072353.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch {epoch} loss {loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_37/1633072353.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, criterion, device, scaler)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/tmp/ipykernel_37/3414392125.py\", line 19, in __getitem__\n    arr = ds.pixel_array\n          ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pydicom/dataset.py\", line 2193, in pixel_array\n    self.convert_pixel_data()\n  File \"/usr/local/lib/python3.11/dist-packages/pydicom/dataset.py\", line 1726, in convert_pixel_data\n    self._pixel_array = pixel_array(self, **opts)\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pydicom/pixels/utils.py\", line 1430, in pixel_array\n    return decoder.as_array(\n           ^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pydicom/pixels/decoders/base.py\", line 982, in as_array\n    self._validate_plugins(decoding_plugin),\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pydicom/pixels/common.py\", line 257, in _validate_plugins\n    raise RuntimeError(\nRuntimeError: Unable to decompress 'JPEG Lossless, Non-Hierarchical, First-Order Prediction (Process 14 [Selection Value 1])' pixel data because all plugins are missing dependencies:\n\tgdcm - requires gdcm>=3.0.10\n\tpylibjpeg - requires pylibjpeg>=2.0 and pylibjpeg-libjpeg>=2.1\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_37/3414392125.py\", line 21, in __getitem__\n    ds.decompress()\n  File \"/usr/local/lib/python3.11/dist-packages/pydicom/dataset.py\", line 2097, in decompress\n    decompress(\n  File \"/usr/local/lib/python3.11/dist-packages/pydicom/pixels/utils.py\", line 565, in decompress\n    raise RuntimeError(\nRuntimeError: Unable to decompress as the plugins for the 'JPEG Lossless, Non-Hierarchical, First-Order Prediction (Process 14 [Selection Value 1])' decoder are all missing dependencies:\n    gdcm - requires gdcm>=3.0.10\n    pylibjpeg - requires pylibjpeg>=2.0 and pylibjpeg-libjpeg>=2.1\n"],"ename":"RuntimeError","evalue":"Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/tmp/ipykernel_37/3414392125.py\", line 19, in __getitem__\n    arr = ds.pixel_array\n          ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pydicom/dataset.py\", line 2193, in pixel_array\n    self.convert_pixel_data()\n  File \"/usr/local/lib/python3.11/dist-packages/pydicom/dataset.py\", line 1726, in convert_pixel_data\n    self._pixel_array = pixel_array(self, **opts)\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pydicom/pixels/utils.py\", line 1430, in pixel_array\n    return decoder.as_array(\n           ^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pydicom/pixels/decoders/base.py\", line 982, in as_array\n    self._validate_plugins(decoding_plugin),\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pydicom/pixels/common.py\", line 257, in _validate_plugins\n    raise RuntimeError(\nRuntimeError: Unable to decompress 'JPEG Lossless, Non-Hierarchical, First-Order Prediction (Process 14 [Selection Value 1])' pixel data because all plugins are missing dependencies:\n\tgdcm - requires gdcm>=3.0.10\n\tpylibjpeg - requires pylibjpeg>=2.0 and pylibjpeg-libjpeg>=2.1\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_37/3414392125.py\", line 21, in __getitem__\n    ds.decompress()\n  File \"/usr/local/lib/python3.11/dist-packages/pydicom/dataset.py\", line 2097, in decompress\n    decompress(\n  File \"/usr/local/lib/python3.11/dist-packages/pydicom/pixels/utils.py\", line 565, in decompress\n    raise RuntimeError(\nRuntimeError: Unable to decompress as the plugins for the 'JPEG Lossless, Non-Hierarchical, First-Order Prediction (Process 14 [Selection Value 1])' decoder are all missing dependencies:\n    gdcm - requires gdcm>=3.0.10\n    pylibjpeg - requires pylibjpeg>=2.0 and pylibjpeg-libjpeg>=2.1\n","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}